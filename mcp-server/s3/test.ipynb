{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77e6a5a9",
   "metadata": {},
   "source": [
    "# Test Localstack + boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534e0496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting boto3\n",
      "  Downloading boto3-1.38.24-py3-none-any.whl (139 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139 kB 820 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting awscli\n",
      "  Downloading awscli-1.40.23-py3-none-any.whl (4.7 MB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.7 MB 12.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Collecting botocore<1.39.0,>=1.38.24\n",
      "  Downloading botocore-1.38.24-py3-none-any.whl (13.6 MB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13.6 MB 1.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting s3transfer<0.14.0,>=0.13.0\n",
      "  Downloading s3transfer-0.13.0-py3-none-any.whl (85 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85 kB 1.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting rsa<4.8,>=3.1.2\n",
      "  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: PyYAML<6.1,>=3.10 in ./venv/lib/python3.9/site-packages (from awscli) (6.0.2)\n",
      "Collecting colorama<0.4.7,>=0.2.5\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Collecting docutils<=0.19,>=0.18.1\n",
      "  Downloading docutils-0.19-py3-none-any.whl (570 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 570 kB 2.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in ./venv/lib/python3.9/site-packages (from botocore<1.39.0,>=1.38.24->boto3) (2.9.0.post0)\n",
      "Collecting urllib3<1.27,>=1.25.4\n",
      "  Downloading urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 144 kB 2.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in ./venv/lib/python3.9/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.39.0,>=1.38.24->boto3) (1.17.0)\n",
      "Collecting pyasn1>=0.1.3\n",
      "  Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Installing collected packages: urllib3, jmespath, pyasn1, botocore, s3transfer, rsa, docutils, colorama, boto3, awscli\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.4.0\n",
      "    Uninstalling urllib3-2.4.0:\n",
      "      Successfully uninstalled urllib3-2.4.0\n",
      "Successfully installed awscli-1.40.23 boto3-1.38.24 botocore-1.38.24 colorama-0.4.6 docutils-0.19 jmespath-1.0.1 pyasn1-0.6.1 rsa-4.7.2 s3transfer-0.13.0 urllib3-1.26.20\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the '/Users/juanmari/Documents/mcp-cloud-analyzer/venv/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install boto3 awscli\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d682400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '19397434-0a1d-40cd-adad-f8fca4d4c797',\n",
       "  'HostId': 's9lzHYrFp76ZVxRcpX9+5cjAnEH2ROuNkd2BHfIa6UkFVdtjf5mKR3/eTPFvsiP/XV/VLi31234=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'server': 'TwistedWeb/24.3.0',\n",
       "   'date': 'Wed, 28 May 2025 02:28:38 GMT',\n",
       "   'access-control-allow-origin': '*',\n",
       "   'access-control-allow-methods': 'HEAD,GET,PUT,POST,DELETE,OPTIONS,PATCH',\n",
       "   'access-control-allow-headers': 'authorization,cache-control,content-length,content-md5,content-type,etag,location,x-amz-acl,x-amz-content-sha256,x-amz-date,x-amz-request-id,x-amz-security-token,x-amz-tagging,x-amz-target,x-amz-user-agent,x-amz-version-id,x-amzn-requestid,x-localstack-target,amz-sdk-invocation-id,amz-sdk-request,x-amz-log-type',\n",
       "   'access-control-expose-headers': 'etag,x-amz-version-id,x-amz-log-result,x-amz-executed-version,x-amz-function-error',\n",
       "   'vary': 'Origin',\n",
       "   'location': '/my-bucket3',\n",
       "   'x-amz-request-id': '19397434-0a1d-40cd-adad-f8fca4d4c797',\n",
       "   'x-amz-id-2': 's9lzHYrFp76ZVxRcpX9+5cjAnEH2ROuNkd2BHfIa6UkFVdtjf5mKR3/eTPFvsiP/XV/VLi31234=',\n",
       "   'content-length': '0'},\n",
       "  'RetryAttempts': 0},\n",
       " 'Location': '/my-bucket3'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "s3 = boto3.client(\n",
    "    's3',\n",
    "    aws_access_key_id='test',\n",
    "    aws_secret_access_key='test',\n",
    "    region_name='us-east-1',\n",
    "    endpoint_url='http://localhost:4566',  # Localstack S3 endpoint\n",
    ")\n",
    "\n",
    "s3.create_bucket(Bucket='my-bucket')\n",
    "s3.create_bucket(Bucket='my-bucket2')\n",
    "s3.create_bucket(Bucket='my-bucket3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90403fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my-bucket\n",
      "my-bucket2\n",
      "my-bucket3\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "s3 = boto3.client(\n",
    "    's3',\n",
    "    aws_access_key_id='test',\n",
    "    aws_secret_access_key='test',\n",
    "    region_name='us-east-1',\n",
    "    endpoint_url='http://localhost:4566'\n",
    ")\n",
    "\n",
    "response = s3.list_buckets()\n",
    "for bucket in response['Buckets']:\n",
    "    print(bucket['Name'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b0f849",
   "metadata": {},
   "source": [
    "# Functionality #1 & #2: Find buckets/objects that don't follow the naming convention\n",
    "it requires returning the list of bucket and object names, and then the LLM (mcp client) will decide which ones don't follow the naming convention. Tools provided:\n",
    "\n",
    "* list_buckets()\n",
    "* list_objects_v2(Bucket=bucket_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82930c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['my-bucket', 'my-bucket2', 'my-bucket3']\n"
     ]
    }
   ],
   "source": [
    "buckets = s3.list_buckets()['Buckets']\n",
    "print([b['Name'] for b in buckets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da491d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my-bucket [{'Key': 'test.txt', 'LastModified': datetime.datetime(2025, 5, 28, 2, 31, tzinfo=tzutc()), 'ETag': '\"5eb63bbbe01eeed093cb22bb8f5acdc3\"', 'ChecksumAlgorithm': ['CRC32'], 'ChecksumType': 'FULL_OBJECT', 'Size': 11, 'StorageClass': 'STANDARD'}]\n",
      "my-bucket2 [{'Key': 'test2.txt', 'LastModified': datetime.datetime(2025, 5, 28, 2, 31, tzinfo=tzutc()), 'ETag': '\"5eb63bbbe01eeed093cb22bb8f5acdc3\"', 'ChecksumAlgorithm': ['CRC32'], 'ChecksumType': 'FULL_OBJECT', 'Size': 11, 'StorageClass': 'STANDARD'}]\n",
      "my-bucket3 [{'Key': 'test3.txt', 'LastModified': datetime.datetime(2025, 5, 28, 2, 31, tzinfo=tzutc()), 'ETag': '\"5eb63bbbe01eeed093cb22bb8f5acdc3\"', 'ChecksumAlgorithm': ['CRC32'], 'ChecksumType': 'FULL_OBJECT', 'Size': 11, 'StorageClass': 'STANDARD'}]\n"
     ]
    }
   ],
   "source": [
    "buckets = s3.list_buckets()['Buckets']\n",
    "for b in buckets:\n",
    "    objects = s3.list_objects_v2(Bucket=b['Name']).get('Contents', [])\n",
    "    print(b['Name'], objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "35c32580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: there should be a tool to modify the names, it receives the new names from the client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644c0a2d",
   "metadata": {},
   "source": [
    "# Functionality #3: Lifecycle policies\n",
    "Return the lifecycle policies of the S3 buckets, the LLM will analyze if they meet the guidelines. Tools provided:\n",
    "\n",
    "* get_bucket_lifecycle_configuration()\n",
    "* set_bucket_lifecycle_configuration(configuration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ea68e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "# Use LocalStack endpoint and dummy credentials\n",
    "s3 = boto3.client(\n",
    "    's3',\n",
    "    endpoint_url='http://localhost:4566',\n",
    "    aws_access_key_id='test',\n",
    "    aws_secret_access_key='test',\n",
    "    region_name='us-east-1'\n",
    ")\n",
    "\n",
    "bucket_name = 'my-bucket'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd5ecb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify configuration. TODO: this is also a tool\n",
    "lifecycle_configuration = {\n",
    "    'Rules': [\n",
    "        {\n",
    "            'ID': 'TransitionToStandardIA',\n",
    "            'Filter': {'Prefix': ''},\n",
    "            'Status': 'Enabled',\n",
    "            'Transitions': [\n",
    "                {\n",
    "                    'Days': 30,\n",
    "                    'StorageClass': 'STANDARD_IA'\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'ID': 'TransitionToGlacier',\n",
    "            'Filter': {'Prefix': ''},\n",
    "            'Status': 'Enabled',\n",
    "            'Transitions': [\n",
    "                {\n",
    "                    'Days': 90,\n",
    "                    'StorageClass': 'GLACIER'\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'ID': 'ExpireAfter365Days',\n",
    "            'Filter': {'Prefix': ''},\n",
    "            'Status': 'Enabled',\n",
    "            'Expiration': {\n",
    "                'Days': 365\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "response = s3.put_bucket_lifecycle_configuration(\n",
    "    Bucket=bucket_name,\n",
    "    LifecycleConfiguration=lifecycle_configuration\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba951ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lifecycle Rules:\n",
      "{'ID': 'TransitionToStandardIA', 'Filter': {'Prefix': ''}, 'Status': 'Enabled', 'Transitions': [{'Days': 30, 'StorageClass': 'STANDARD_IA'}]}\n",
      "{'ID': 'TransitionToGlacier', 'Filter': {'Prefix': ''}, 'Status': 'Enabled', 'Transitions': [{'Days': 90, 'StorageClass': 'GLACIER'}]}\n",
      "{'Expiration': {'Days': 365}, 'ID': 'ExpireAfter365Days', 'Filter': {'Prefix': ''}, 'Status': 'Enabled'}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    response = s3.get_bucket_lifecycle_configuration(Bucket=bucket_name)\n",
    "    rules = response.get('Rules', [])\n",
    "    print(\"Lifecycle Rules:\")\n",
    "    for rule in rules:\n",
    "        print(rule)\n",
    "except s3.exceptions.ClientError as e:\n",
    "    if e.response['Error']['Code'] == 'NoSuchLifecycleConfiguration':\n",
    "        print(\"No lifecycle configuration found for this bucket.\")\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2894561",
   "metadata": {},
   "source": [
    "# Functionality #4: return versioning status of the S3 buckets\n",
    "Return the versioning status of the S3 buckets, the LLM will analyze if they meet the guidelines. tools provided:\n",
    "\n",
    "* get_bucket_versioning(Bucket=bucket_name)\n",
    "* set_bucket_versioning(Bucket=bucket_name, VersioningConfiguration={'Status': 'Enabled'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "38aad6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versioning status for bucket 'my-bucket': Not enabled\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "s3 = boto3.client(\n",
    "    's3',\n",
    "    endpoint_url='http://localhost:4566',  # Use if working with LocalStack; omit for real AWS\n",
    "    aws_access_key_id='test',               # Use your credentials for real AWS\n",
    "    aws_secret_access_key='test',\n",
    "    region_name='us-east-1'\n",
    ")\n",
    "\n",
    "bucket_name = 'my-bucket'\n",
    "\n",
    "response = s3.get_bucket_versioning(Bucket=bucket_name)\n",
    "status = response.get('Status', 'Not enabled')\n",
    "\n",
    "print(f\"Versioning status for bucket '{bucket_name}': {status}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c736889c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable versioning\n",
    "s3.put_bucket_versioning(\n",
    "    Bucket=bucket,\n",
    "    VersioningConfiguration={'Status': 'Enabled'}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba37511",
   "metadata": {},
   "source": [
    "# Functionality #5: ACCESS CONTROL & PERMISSIONS\n",
    "Return the list of buckets and objects that have public access enabled, the LLM will analyze if they meet the guidelines. tools provided:\n",
    "\n",
    "* list_buckets()\n",
    "* list_objects_v2(Bucket=bucket_name)\n",
    "* get_bucket_acl(Bucket=bucket_name)\n",
    "* get_object_acl(Bucket=bucket_name, Key=key_name)\n",
    "\n",
    "This functionality could also include tools to analyze IAM service, instead of the ACLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7b98db62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Public Access Block settings for my-bucket:\n",
      "{'BlockPublicAcls': True, 'IgnorePublicAcls': True, 'BlockPublicPolicy': True, 'RestrictPublicBuckets': True}\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "s3 = boto3.client(\n",
    "    's3',\n",
    "    endpoint_url='http://localhost:4566',  # Use if working with LocalStack; omit for real AWS\n",
    "    aws_access_key_id='test',               # Use your credentials for real AWS\n",
    "    aws_secret_access_key='test',\n",
    "    region_name='us-east-1'\n",
    ")\n",
    "\n",
    "bucket_name = 'my-bucket'\n",
    "\n",
    "try:\n",
    "    response = s3.get_public_access_block(Bucket=bucket_name)\n",
    "    pab = response['PublicAccessBlockConfiguration']\n",
    "    print(f\"Public Access Block settings for {bucket_name}:\")\n",
    "    print(pab)\n",
    "except Exception as e:\n",
    "    print(f\"No Public Access Block configuration set for {bucket_name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458598d3",
   "metadata": {},
   "source": [
    "# Functionality #6: Encryption\n",
    "For each bucket, check if it has encryption enabled and if it is using the correct encryption method. If not, it can configured. Tools provided:\n",
    "\n",
    "* get_bucket_encryption(Bucket=bucket_name)\n",
    "* put_bucket_encryption(Bucket=bucket_name, ServerSideEncryptionConfiguration=encryption_config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "46103b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encryption algorithm: aws:kms\n",
      "KMS Key ID: None\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "s3 = boto3.client(\n",
    "    's3',\n",
    "    endpoint_url='http://localhost:4566',  # Remove for real AWS\n",
    "    aws_access_key_id='test',\n",
    "    aws_secret_access_key='test',\n",
    "    region_name='us-east-1'\n",
    ")\n",
    "\n",
    "bucket_name = 'my-bucket'\n",
    "\n",
    "try:\n",
    "    response = s3.get_bucket_encryption(Bucket=bucket_name)\n",
    "    rules = response['ServerSideEncryptionConfiguration']['Rules']\n",
    "    \n",
    "    for rule in rules:\n",
    "        algo = rule['ApplyServerSideEncryptionByDefault']['SSEAlgorithm']\n",
    "        kms_key = rule['ApplyServerSideEncryptionByDefault'].get('KMSMasterKeyID')\n",
    "        print(f\"Encryption algorithm: {algo}\")\n",
    "        if algo == 'aws:kms':\n",
    "            print(f\"KMS Key ID: {kms_key}\")\n",
    "except ClientError as e:\n",
    "    if e.response['Error']['Code'] == 'ServerSideEncryptionConfigurationNotFoundError':\n",
    "        print(f\"No server-side encryption configured for bucket: {bucket_name}\")\n",
    "    else:\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725c6fee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '5cf01051-c58f-4a95-885f-2cc7ba4c41af',\n",
       "  'HostId': 's9lzHYrFp76ZVxRcpX9+5cjAnEH2ROuNkd2BHfIa6UkFVdtjf5mKR3/eTPFvsiP/XV/VLi31234=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'server': 'TwistedWeb/24.3.0',\n",
       "   'date': 'Wed, 28 May 2025 03:29:37 GMT',\n",
       "   'x-amz-request-id': '5cf01051-c58f-4a95-885f-2cc7ba4c41af',\n",
       "   'x-amz-id-2': 's9lzHYrFp76ZVxRcpX9+5cjAnEH2ROuNkd2BHfIa6UkFVdtjf5mKR3/eTPFvsiP/XV/VLi31234=',\n",
       "   'content-length': '0'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3.put_bucket_encryption(\n",
    "    Bucket=bucket_name,\n",
    "    ServerSideEncryptionConfiguration={\n",
    "        'Rules': [\n",
    "            {\n",
    "                'ApplyServerSideEncryptionByDefault': {\n",
    "                    'SSEAlgorithm': 'aws:kms'  # or 'aws:kms'\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c786c5a2",
   "metadata": {},
   "source": [
    "# Functionality #7: Find duplicates \n",
    "\n",
    "You typically consider files \"duplicates\" if they match:\n",
    "\n",
    "âœ… Content hash (body) (e.g., MD5 or SHA256)\n",
    "\n",
    "ðŸŸ¡ Optional: File name or metadata (for more context)\n",
    "\n",
    "Tools provided:\n",
    "\n",
    "* get_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47a4d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "s3 = boto3.client(\n",
    "    's3',\n",
    "    aws_access_key_id='test',\n",
    "    aws_secret_access_key='test',\n",
    "    region_name='us-east-1',\n",
    "    endpoint_url='http://localhost:4566',  # Localstack S3 endpoint\n",
    ")\n",
    "\n",
    "s3.create_bucket(Bucket='my-bucket')\n",
    "s3.create_bucket(Bucket='my-bucket2')\n",
    "s3.create_bucket(Bucket='my-bucket3')\n",
    "\n",
    "s3.put_object(Bucket='my-bucket', Key='test.txt', Body='hello world')\n",
    "response = s3.get_object(Bucket='my-bucket', Key='test.txt')\n",
    "print(response['Body'].read().decode())\n",
    "\n",
    "s3.put_object(Bucket='my-bucket2', Key='test2.txt', Body='hello world')\n",
    "response = s3.get_object(Bucket='my-bucket2', Key='test2.txt')\n",
    "print(response['Body'].read().decode())\n",
    "\n",
    "\n",
    "s3.put_object(Bucket='my-bucket3', Key='test3.txt', Body='hello world')\n",
    "response = s3.get_object(Bucket='my-bucket3', Key='test3.txt')\n",
    "print(response['Body'].read().decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817ca235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use list_objects_v2 to retrieve object keys and metadata from each bucket.\n",
    "\n",
    "buckets = s3.list_buckets()['Buckets']\n",
    "for b in buckets:\n",
    "    objects = s3.list_objects_v2(Bucket=b['Name']).get('Contents', [])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b12305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use get_object() and compute the hash manually (since the ETag is only a reliable MD5 for non-multipart, unencrypted files).\n",
    "import hashlib\n",
    "\n",
    "def hash_object(bucket, key):\n",
    "    obj = s3.get_object(Bucket=bucket, Key=key)\n",
    "    body = obj['Body'].read()\n",
    "    return hashlib.md5(body).hexdigest()  # or use sha256\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a084ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping of hashes to (bucket, key) pairs.\n",
    "\n",
    "duplicates = {}\n",
    "hash_map = {}\n",
    "bucket_names = [bucket['Name'] for bucket in s3.list_buckets()['Buckets']]\n",
    "for bucket in bucket_names:\n",
    "    objects = s3.list_objects_v2(Bucket=bucket).get('Contents', [])\n",
    "    for obj in objects:\n",
    "        key = obj['Key']\n",
    "        file_hash = hash_object(bucket, key)\n",
    "\n",
    "        if file_hash in hash_map:\n",
    "            # Duplicate found\n",
    "            duplicates.setdefault(file_hash, []).append((bucket, key))\n",
    "        else:\n",
    "            hash_map[file_hash] = (bucket, key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70866f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Duplicate hash: 5eb63bbbe01eeed093cb22bb8f5acdc3\n",
      " - s3://my-bucket2/test2.txt\n",
      " - s3://my-bucket3/test3.txt\n"
     ]
    }
   ],
   "source": [
    "for file_hash, locations in duplicates.items():\n",
    "    print(f\"\\nDuplicate hash: {file_hash}\")\n",
    "    for bucket, key in locations:\n",
    "        print(f\" - s3://{bucket}/{key}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f74e7380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement mcp (from versions: none)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for mcp\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the '/Users/juanmari/Documents/mcp-cloud-analyzer/venv/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install mcp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dd5355",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
